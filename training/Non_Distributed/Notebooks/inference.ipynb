{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('opt': conda)"
  },
  "interpreter": {
   "hash": "c172d229f9980eb2e9bbd8bad79123e0519bc8b7784791961971fb2eb2efb7c2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(1, '/Users/swastik/ophthalmology/Project_Quality_Assurance/From_Bascom/Hold_out/') # noqa\n",
    "sys.path.insert(1,'/Users/swastik/ophthalmology/Project_Quality_Assurance/Final_QA_FDA/Application/training/Non_Distributed') # noqa\n",
    "from import_packages.dataset_class import Dataset\n",
    "from import_packages.train_val_to_ids import inference_val_to_ids\n",
    "from import_packages.checkpoint import load_checkpoint\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in /opt/miniconda3/envs/opt/lib/python3.7/site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/opt/lib/python3.7/site-packages (from efficientnet_pytorch) (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '/Users/swastik/ophthalmology/Project_Quality_Assurance/Final_QA_FDA/data_models/chocolate_feather/df_val.csv' # noqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       img  Excellent  Good  Adequate  Insuff_for_full  \\\n",
       "0    20170120223854648.JPG          1     0         0                0   \n",
       "1       299458_2024651.JPG          0     0         0                1   \n",
       "2       301839_2043723.JPG          1     0         0                0   \n",
       "3       294432_1985275.JPG          1     0         0                0   \n",
       "4       272650_1820786.JPG          0     0         0                1   \n",
       "..                     ...        ...   ...       ...              ...   \n",
       "758     324765_2224415.JPG          0     0         0                1   \n",
       "759       007-8834-605.JPG          0     0         0                0   \n",
       "760  20170430193513456.JPG          0     1         0                0   \n",
       "761     257895_1711283.JPG          0     1         0                0   \n",
       "762     277006_1854228.JPG          0     0         1                0   \n",
       "\n",
       "     Insuff_for_any  labels  Redfree  other  \n",
       "0                 0       0      NaN    NaN  \n",
       "1                 0       2      NaN    NaN  \n",
       "2                 0       0      NaN    NaN  \n",
       "3                 0       0      NaN    NaN  \n",
       "4                 0       2      NaN    NaN  \n",
       "..              ...     ...      ...    ...  \n",
       "758               0       2      NaN    NaN  \n",
       "759               1       2      NaN    NaN  \n",
       "760               0       1      NaN    NaN  \n",
       "761               0       1      NaN    NaN  \n",
       "762               0       1      NaN    NaN  \n",
       "\n",
       "[763 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img</th>\n      <th>Excellent</th>\n      <th>Good</th>\n      <th>Adequate</th>\n      <th>Insuff_for_full</th>\n      <th>Insuff_for_any</th>\n      <th>labels</th>\n      <th>Redfree</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20170120223854648.JPG</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>299458_2024651.JPG</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>301839_2043723.JPG</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>294432_1985275.JPG</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>272650_1820786.JPG</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>758</th>\n      <td>324765_2224415.JPG</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>759</th>\n      <td>007-8834-605.JPG</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>20170430193513456.JPG</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>257895_1711283.JPG</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>277006_1854228.JPG</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>763 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv(path_dir).iloc[:, 2:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/Users/swastik/ophthalmology/Project_Quality_Assurance/Final_QA_FDA/Data_Staging/Combined_Dataset_224' # noqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# CuDA Determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "batch_size = 2\n",
    "partition, labels = inference_val_to_ids(csv_file=path_dir, stratify_columns='labels') # noqa\n",
    "test_set = Dataset(partition['test_set'],labels,root_dir=source_dir,test_transform=True) # noqa\n",
    "test_loader = torch.utils.data.DataLoader(test_set,shuffle=True,pin_memory=True, num_workers =4, batch_size=batch_size) # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "model_transfer = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "n_inputs = model_transfer._fc.in_features\n",
    "model_transfer._fc = nn.Linear(n_inputs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = torch.tensor([0.0008, 0.0001, 0.0003])\n",
    "optimizer = torch.optim.SGD(model_transfer.parameters(), lr=3e-4)\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            patience=4,\n",
    "            factor=0.1,\n",
    "            mode='min',\n",
    "            verbose=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "else:\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(checkpoint_path='/Users/swastik/ophthalmology/Project_Quality_Assurance/Final_QA_FDA/Data_models/chocolate_feather/checkpoint_224.pt',model = model_transfer) # noqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader, criterion, use_cuda=False):\n",
    "    \"\"\"Calculate Accuracy.\"\"\"\n",
    "    test_accuracy = 0.0\n",
    "    test_correct = 0.0\n",
    "    test_total = 0.0\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # print(\"data shape:\", data.shape)\n",
    "        # print(\"target shape:\", target.shape)\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # update the average validation loss\n",
    "        output = model(data).squeeze()\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        test_correct += np.sum(np.squeeze(pred.eq(target.view_as(pred)).cpu().numpy())) # noqa\n",
    "        test_total += data.size(0)\n",
    "    test_accuracy = 100. * (test_correct/test_total)\n",
    "    print(test_accuracy)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 3, 224, 224])\n",
      "tensor([[0.0501, 0.4176, 0.5324],\n",
      "        [0.2734, 0.5931, 0.1335]], grad_fn=<SqueezeBackward0>)\n",
      "torch.Size([2])\n",
      "Next tensor\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    print(data.shape)\n",
    "    output = torch.nn.functional.softmax(model(data),dim=1).squeeze()\n",
    "    print(output)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    print(pred.shape)\n",
    "    print(\"Next tensor\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5531f0872f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "output = output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.38250783"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "pred = torch.argmax(a, dim=1)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-52beb20edcf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_transfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-01c9404f53d2>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(model, loader, criterion, use_cuda)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# update the average validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtest_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "accuracy(model, test_loader, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Excellent', 'Good_Adequate', 'Insufficient_for_Any_All']"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "response = open(\"/Users/swastik/ophthalmology/Project_Quality_Assurance/Final_QA_FDA/Application/Quality_scanner/gradio_UI/label_names.txt\",\"r\") # noqa\n",
    "labels = [line.rstrip('\\n') for line in response]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}